{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suffering-volunteer",
   "metadata": {},
   "source": [
    "# Preparation for Building CNN Model: Define Supporting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-steps",
   "metadata": {},
   "source": [
    "### Initialize Wegihts in Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "headed-festival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def initialize_weights (filter_shape):\n",
    "    inti_random = tf.truncated_normal(filter_shape, stddev = 0.1)\n",
    "    return (tf.Variable(inti_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-union",
   "metadata": {},
   "source": [
    "### Initialize Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "distant-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias (bias_shape):\n",
    "    inti_bias = tf.constant(0.1, shape=bias_shape)\n",
    "    return (tf.Variable(inti_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-medication",
   "metadata": {},
   "source": [
    "### Set Up Convolutional Layer and Perform Convolution: Dot Product(x *W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "retired-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_layer_and_compute_dot(inputs, filter_shape):\n",
    "    filter_inti_with_weight = initialize_weights(filter_shape)\n",
    "    conv_layer_out = tf.nn.conv2d(inputs, filter_inti_with_weight, strides=[1,1,1,1], padding = 'SAME')\n",
    "    return(conv_layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-component",
   "metadata": {},
   "source": [
    "### Set Up Convolutional Layer and Perform Convolution: Dot Product + bias (x *W+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "consecutive-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = output from convolution_layer\n",
    "#filter_shape = the elements number of the convolution layer which has 4 elements, so [3]\n",
    "def create_relu(inputs, filter_shape):\n",
    "    b = initialize_bias([filter_shape[3]])\n",
    "    relu_layer = tf.nn.relu(inputs+b)\n",
    "    return(relu_layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-mistress",
   "metadata": {},
   "source": [
    "### Set Up pooling Layer and reduce spatial size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "confirmed-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_maxpooling_reduce(inputs):\n",
    "    pooling_layer_outputs = tf.nn.max_pool(inputs, ksize=[1,2,2,1], strides=[1,2,2,1], padding = 'SAME')\n",
    "    return (pooling_layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-confidence",
   "metadata": {},
   "source": [
    "### Set Up Fully Connected Layer and Perform Computation: (inputs*Weight)+Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "informational-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fully_connect_layer_and_compute_dotproduct_plus_bias(inputs,output_size):\n",
    "    input_size = int(inputs.get_shape()[1])\n",
    "    W = initialize_weights([input_size,output_size])\n",
    "    b = initialize_bias ([output_size])\n",
    "    fc = tf.matmul(inputs,W)+b\n",
    "    return(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-defensive",
   "metadata": {},
   "source": [
    " ### Phase I : Build the Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "southeast-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,784])\n",
    "y_true = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-copper",
   "metadata": {},
   "source": [
    "### Reshape the Input Placeholder x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "difficult-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 is gray scale\n",
    "-1 is reshape to be the same scale as the old one\n",
    "\"\"\"\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-length",
   "metadata": {},
   "source": [
    "### Create 1st Convolution Layer, ReLU Layer, and Perform Computational: x*W+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "chinese-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1_out \\\n",
    "    = create_convolutional_layer_and_compute_dot(x_image, filter_shape = [4,4,1,32])\n",
    "\n",
    "relu_layer_1 \\\n",
    "    =create_relu(conv_layer_1_out, filter_shape = [4,4,1,32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-middle",
   "metadata": {},
   "source": [
    "### Create 1st Pooling Layer and Reduce Spatial Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pregnant-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer_1_outputs = create_maxpooling_reduce(relu_layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-delta",
   "metadata": {},
   "source": [
    "### Create 2nd Convolution Layer, ReLU Layer, and Perform Computational: x*W+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "vietnamese-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2_out \\\n",
    "    = create_convolutional_layer_and_compute_dot(pooling_layer_1_outputs, filter_shape = [4,4,32,64])\n",
    "\n",
    "relu_layer_2 \\\n",
    "    =create_relu(conv_layer_2_out, filter_shape = [4,4,32,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-villa",
   "metadata": {},
   "source": [
    "### Create 2nd Pooling Layer and Reduce Spatial Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stainless-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer_2_outputs = create_maxpooling_reduce(relu_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-advancement",
   "metadata": {},
   "source": [
    "### Reshape/Flatten Data Making It Ready to be Fed Into 1st FC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "surprised-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer_2_outputs_flat =  tf.reshape(pooling_layer_2_outputs, [-1,7 * 7 * 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-prophet",
   "metadata": {},
   "source": [
    "### Create 1st FC Layer,ReLU Layer, and Output Data to Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acoustic-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_1_outputs = create_fully_connect_layer_and_compute_dotproduct_plus_bias(pooling_layer_2_outputs_flat, output_size = 1024)\n",
    "fc_relu_1=tf.nn.relu(fc_layer_1_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-compilation",
   "metadata": {},
   "source": [
    "### Create Dropout Layer and Dropout a Fraction of Outputs Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "extensive-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)\n",
    "fc_dropout = tf.nn.dropout(fc_relu_1,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-craps",
   "metadata": {},
   "source": [
    "### Create Final FC Layer, Compute (xW+b), and Product Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "needed-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = create_fully_connect_layer_and_compute_dotproduct_plus_bias(fc_dropout, output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-chancellor",
   "metadata": {},
   "source": [
    "### Define Loss Function and Calculate Softmax Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "confirmed-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_corss_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits = Y_pred)\n",
    "cross_entropy_mean = tf.reduce_mean(softmax_corss_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-islam",
   "metadata": {},
   "source": [
    "### Create an Optimize CNN Model and Set Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "powered-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-incident",
   "metadata": {},
   "source": [
    "### Create a Trainer to train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "incident-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer = optimizer.minimize(cross_entropy_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-movie",
   "metadata": {},
   "source": [
    "## Train and Test CNN Deep learning model on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-daisy",
   "metadata": {},
   "source": [
    "### Initialize All Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "greenhouse-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_initializer = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-distinction",
   "metadata": {},
   "source": [
    "### Set the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "green-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-egyptian",
   "metadata": {},
   "source": [
    "### Run tf.Session() to Train and Test Deep Learning CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "express-mining",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tON STEP\t\tACCURACY\n",
      "\t0 \t\t 0.1301\n",
      "\t100 \t\t 0.9316\n",
      "\t200 \t\t 0.9609\n",
      "\t300 \t\t 0.9666\n",
      "\t400 \t\t 0.9726\n",
      "\t500 \t\t 0.9714\n",
      "\t600 \t\t 0.9777\n",
      "\t700 \t\t 0.9792\n",
      "\t800 \t\t 0.9815\n",
      "\t900 \t\t 0.9811\n",
      "\t1000 \t\t 0.9827\n",
      "\t1100 \t\t 0.9853\n",
      "\t1200 \t\t 0.9855\n",
      "\t1300 \t\t 0.9855\n",
      "\t1400 \t\t 0.9822\n",
      "\t1500 \t\t 0.9828\n",
      "\t1600 \t\t 0.988\n",
      "\t1700 \t\t 0.9887\n",
      "\t1800 \t\t 0.9862\n",
      "\t1900 \t\t 0.9886\n",
      "\t2000 \t\t 0.9894\n",
      "\t2100 \t\t 0.9893\n",
      "\t2200 \t\t 0.9895\n",
      "\t2300 \t\t 0.9878\n",
      "\t2400 \t\t 0.9893\n",
      "\t2500 \t\t 0.9887\n",
      "\t2600 \t\t 0.9876\n",
      "\t2700 \t\t 0.9906\n",
      "\t2800 \t\t 0.99\n",
      "\t2900 \t\t 0.989\n",
      "\t3000 \t\t 0.9909\n",
      "\t3100 \t\t 0.9891\n",
      "\t3200 \t\t 0.9897\n",
      "\t3300 \t\t 0.9906\n",
      "\t3400 \t\t 0.9928\n",
      "\t3500 \t\t 0.9902\n",
      "\t3600 \t\t 0.9905\n",
      "\t3700 \t\t 0.9906\n",
      "\t3800 \t\t 0.9905\n",
      "\t3900 \t\t 0.9907\n",
      "\t4000 \t\t 0.9909\n",
      "\t4100 \t\t 0.9911\n",
      "\t4200 \t\t 0.9872\n",
      "\t4300 \t\t 0.9915\n",
      "\t4400 \t\t 0.9911\n",
      "\t4500 \t\t 0.99\n",
      "\t4600 \t\t 0.9906\n",
      "\t4700 \t\t 0.9919\n",
      "\t4800 \t\t 0.9919\n",
      "\t4900 \t\t 0.99\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(vars_initializer)\n",
    "    print('\\tON STEP\\t\\tACCURACY')\n",
    "    for i in range (steps):\n",
    "        batch_x, batch_y = mnist.train.next_batch(50)\n",
    "        sess.run(cnn_trainer, feed_dict={x: batch_x, y_true: batch_y, hold_prob:0.5})\n",
    "        if i % 100 == 0:\n",
    "            matches = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(y_true, 1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "            test_accuracy = sess.run( acc, feed_dict={x:mnist.test.images, \\\n",
    "                                                      y_true:mnist.test.labels, \\\n",
    "                                                      hold_prob: 1.0} )\n",
    "            print('\\t{}'.format(i), '\\t\\t', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
